# ğŸ•¸ï¸ æ•°æ®æµè¯¦è§£

> è¯¦ç»†è§£é‡Šç³»ç»Ÿä¸­çš„3æ¡æ ¸å¿ƒæ•°æ®æµ  
> é˜…è¯»æ—¶é—´: 20åˆ†é’Ÿ

---

## ğŸ“‹ æ ¸å¿ƒæ•°æ®æµ

ç³»ç»Ÿæœ‰3æ¡æ ¸å¿ƒæ•°æ®æµï¼š
1. **æ–‡æ¡£ä¸Šä¼ ä¸åŒæ­¥æµ** - RAGFlow â†’ SQLite
2. **çŸ¥è¯†å›¾è°±æ„å»ºæµ** - RAGFlow + Qwen â†’ SQLite
3. **æ™ºèƒ½é—®ç­”æµ** - RAGFlow Chat Assistant â†’ ç”¨æˆ·

---

## 1ï¸âƒ£ æ–‡æ¡£ä¸Šä¼ ä¸åŒæ­¥æµ

### å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘  ä¸Šä¼ PDF/DOCX
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAGFlow Webç•Œé¢ â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘¡ è‡ªåŠ¨å¤„ç†
       â”œâ”€ æ–‡æœ¬æå–
       â”œâ”€ åˆ†å— (chunking)
       â”œâ”€ å‘é‡åŒ– (embedding)
       â””â”€ å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAGFlowçŸ¥è¯†åº“   â”‚
â”‚ - documents     â”‚
â”‚ - chunks        â”‚
â”‚ - vectors       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘¢ DocumentsPageè§¦å‘åŒæ­¥
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataSyncService         â”‚
â”‚ sync_documents_to_database() â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘£ è°ƒç”¨RAGFlow API
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAGFlowClient   â”‚
â”‚ get_documents() â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘¤ è¿”å›æ–‡æ¡£å…ƒæ•°æ®
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PolicyDAO       â”‚
â”‚ create_policy() â”‚
â”‚ update_policy() â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ â‘¥ å­˜å‚¨åˆ°SQLite
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQLite policies â”‚
â”‚ - id            â”‚
â”‚ - ragflow_id    â”‚
â”‚ - title         â”‚
â”‚ - policy_type   â”‚
â”‚ - region        â”‚
â”‚ - ...           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤â‘ : ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£
```bash
# è®¿é—®RAGFlow Webç•Œé¢
http://localhost:9380

# ç™»å½•åè¿›å…¥çŸ¥è¯†åº“ç®¡ç†
# é€‰æ‹©çŸ¥è¯†åº“: policy_demo_kb
# ç‚¹å‡»"ä¸Šä¼ æ–‡æ¡£"
# é€‰æ‹©æ–‡ä»¶: ç§‘æŠ€åˆ›æ–°æ”¿ç­–.pdf
# ç‚¹å‡»"ç¡®å®š"
```

---

#### æ­¥éª¤â‘¡: RAGFlowè‡ªåŠ¨å¤„ç†
```python
# RAGFlowå†…éƒ¨æµç¨‹ï¼ˆè‡ªåŠ¨ï¼‰
1. æ–‡æœ¬æå–
   - PDF â†’ çº¯æ–‡æœ¬
   - ä¿ç•™æ ¼å¼ï¼ˆæ ‡é¢˜ã€æ®µè½ã€è¡¨æ ¼ç­‰ï¼‰

2. æ™ºèƒ½åˆ†å— (Chunking)
   - æ ¹æ®è¯­ä¹‰è¾¹ç•Œåˆ‡åˆ†
   - å—å¤§å°: 512 tokens (å¯é…ç½®)
   - å—é‡å : 50 tokens
   - ç”Ÿæˆchunk_id

3. å‘é‡åŒ– (Embedding)
   - è°ƒç”¨åµŒå…¥æ¨¡å‹ï¼ˆå¦‚BGEã€OpenAI Ada-002ï¼‰
   - ç”Ÿæˆ768ç»´å‘é‡ï¼ˆæ ¹æ®æ¨¡å‹ï¼‰
   - å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“

4. å…ƒæ•°æ®æå–
   - æ–‡ä»¶åã€å¤§å°ã€ä¸Šä¼ æ—¶é—´
   - chunkæ•°é‡ã€tokenæ•°é‡
   - æ–‡æ¡£çŠ¶æ€ï¼ˆprocessing â†’ completedï¼‰
```

---

#### æ­¥éª¤â‘¢: è§¦å‘åŒæ­¥
```python
# src/pages/documents_page.py
def show():
    st.title("ğŸ“„ æ–‡æ¡£ç®¡ç†")
    
    if st.button("ğŸ”„ åŒæ­¥æ–‡æ¡£åˆ°æœ¬åœ°æ•°æ®åº“"):
        with st.spinner("æ­£åœ¨åŒæ­¥..."):
            sync_service = DataSyncService()
            result = sync_service.sync_documents_to_database("policy_demo_kb")
            
            st.success(f"åŒæ­¥å®Œæˆï¼æ–°å¢/æ›´æ–°: {result['synced_count']} ä¸ªæ–‡æ¡£")
```

---

#### æ­¥éª¤â‘£: è°ƒç”¨RAGFlow API
```python
# src/services/data_sync.py
def sync_documents_to_database(self, kb_name: str) -> Dict:
    # 1. è·å–RAGFlowæ–‡æ¡£åˆ—è¡¨
    ragflow_client = get_ragflow_client()
    documents = ragflow_client.get_documents(kb_name)
    
    # 2. éå†æ¯ä¸ªæ–‡æ¡£
    synced_count = 0
    skipped_count = 0
    
    for doc in documents:
        doc_id = doc['id']
        
        # 3. æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²å­˜åœ¨
        policy_dao = get_policy_dao()
        existing_policy = policy_dao.get_policy_by_ragflow_id(doc_id)
        
        # 4. æå–å…ƒæ•°æ®
        metadata = {
            'ragflow_id': doc_id,
            'title': doc['name'].replace('.pdf', ''),
            'size': doc.get('size', 0),
            'chunk_count': doc.get('chunk_count', 0),
            'token_count': doc.get('token_count', 0),
            'created_at': doc.get('created_at'),
            # ...æ›´å¤šå­—æ®µä»MetadataExtractoræå–
        }
        
        # 5. åˆ›å»ºæˆ–æ›´æ–°
        if existing_policy is None:
            policy_dao.create_policy(metadata)
            synced_count += 1
        else:
            policy_dao.update_policy(existing_policy.id, metadata)
            synced_count += 1
    
    return {
        'synced_count': synced_count,
        'skipped_count': skipped_count
    }
```

---

#### æ­¥éª¤â‘¤: å…ƒæ•°æ®æå–ï¼ˆå¯é€‰ï¼‰
```python
# src/business/metadata_extractor.py
class MetadataExtractor:
    def extract_all(self, content: str) -> Dict:
        """ä»æ”¿ç­–æ–‡æœ¬æå–å…ƒæ•°æ®"""
        return {
            'policy_type': self._extract_policy_type(content),
            'issuing_authority': self._extract_authority(content),
            'region': self._extract_region(content),
            'document_number': self._extract_doc_number(content),
            'effective_date': self._extract_effective_date(content)
        }
    
    def _extract_authority(self, content: str) -> str:
        """æå–å‘æ–‡æœºå…³"""
        # æ­£åˆ™åŒ¹é…: "XXçœXXå…", "å›½åŠ¡é™¢", "XXå¸‚æ”¿åºœ"ç­‰
        patterns = [
            r'([\u4e00-\u9fa5]+çœ[\u4e00-\u9fa5]+å…)',
            r'([\u4e00-\u9fa5]+å¸‚[\u4e00-\u9fa5]+å±€)',
            r'(å›½åŠ¡é™¢|å‘æ”¹å§”|è´¢æ”¿éƒ¨)',
        ]
        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                return match.group(1)
        return "æœªçŸ¥"
```

---

#### æ­¥éª¤â‘¥: å­˜å‚¨åˆ°SQLite
```python
# src/database/policy_dao.py
def create_policy(self, metadata: Dict) -> int:
    conn = self.db_manager.get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO policies (
            ragflow_id, title, policy_type, region,
            issuing_authority, document_number,
            effective_date, expiry_date, status,
            content, summary, chunk_count, token_count,
            created_at, updated_at
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        metadata['ragflow_id'],
        metadata['title'],
        metadata.get('policy_type', ''),
        metadata.get('region', ''),
        metadata.get('issuing_authority', ''),
        metadata.get('document_number', ''),
        metadata.get('effective_date'),
        metadata.get('expiry_date'),
        metadata.get('status', 'æœ‰æ•ˆ'),
        metadata.get('content', ''),
        metadata.get('summary', ''),
        metadata.get('chunk_count', 0),
        metadata.get('token_count', 0),
        datetime.now(),
        datetime.now()
    ))
    
    conn.commit()
    return cursor.lastrowid
```

---

### æ•°æ®å¯¹æ¯”

| æ•°æ® | RAGFlow | SQLite |
|-----|---------|--------|
| æ–‡æ¡£å®Œæ•´å†…å®¹ | âœ… Chunksæ‹¼æ¥ | âŒ ä¸å­˜å‚¨ï¼ˆèŠ‚çœç©ºé—´ï¼‰ |
| å‘é‡åµŒå…¥ | âœ… 768ç»´å‘é‡ | âŒ ä¸å­˜å‚¨ |
| å…ƒæ•°æ® | âœ… åŸºç¡€å…ƒæ•°æ® | âœ… å¢å¼ºå…ƒæ•°æ® |
| æ”¿ç­–ç±»å‹ | âŒ | âœ… è‡ªåŠ¨æå– |
| å‘æ–‡æœºå…³ | âŒ | âœ… è‡ªåŠ¨æå– |
| æ—¶æ•ˆæ€§åˆ†æ | âŒ | âœ… æœ‰æ•ˆ/è¿‡æœŸ |
| æ ‡ç­¾ä½“ç³» | âŒ | âœ… tagsè¡¨ |

**è®¾è®¡æ€è·¯**: RAGFlowè´Ÿè´£å‘é‡æ£€ç´¢ï¼ŒSQLiteè´Ÿè´£ç»“æ„åŒ–æŸ¥è¯¢å’Œåˆ†æ

---

## 2ï¸âƒ£ çŸ¥è¯†å›¾è°±æ„å»ºæµ

### å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GraphPage    â”‚ ç”¨æˆ·ç‚¹å‡»"æ„å»ºå›¾è°±"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataSyncService          â”‚
â”‚ build_knowledge_graph()  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                             â”‚
       â†“                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚RAGFlowClient â”‚            â”‚ GraphDAO     â”‚
â”‚get_documents()â”‚            â”‚load_graph()  â”‚ (å¦‚æœå¢é‡æ„å»º)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                             â”‚
       â†“                             â†“
  éå†æ¯ä¸ªæ–‡æ¡£                   å·²å¤„ç†æ–‡æ¡£åˆ—è¡¨
       â”‚
       â”œâ”€ get_document_content(doc_id)  # è·å–å®Œæ•´å†…å®¹
       â”‚  â””â”€ æ‹¼æ¥æ‰€æœ‰chunks
       â”‚
       â”œâ”€ QwenClient.extract_entities_and_relations(content)
       â”‚  â”œâ”€ åŠ è½½æç¤ºè¯æ¨¡æ¿
       â”‚  â”œâ”€ è°ƒç”¨Qwen API
       â”‚  â”œâ”€ è§£æJSONè¿”å›
       â”‚  â””â”€ è¿”å› {entities: [...], relations: [...]}
       â”‚
       â”œâ”€ æ„å»ºGraphNodeå¯¹è±¡
       â”‚  â””â”€ å»é‡ï¼ˆèŠ‚ç‚¹IDã€æ–‡æ¡£åå».pdfåç¼€ï¼‰
       â”‚
       â”œâ”€ æ„å»ºGraphEdgeå¯¹è±¡
       â”‚  â””â”€ éªŒè¯source/targetå­˜åœ¨
       â”‚
       â””â”€ ç´¯ç§¯åˆ°graph_data
              â”‚
              â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ GraphDAO     â”‚
       â”‚ save_graph() â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ SQLite           â”‚
       â”‚ knowledge_graph  â”‚
       â”‚ - graph_data (JSON) â”‚
       â”‚ - node_count     â”‚
       â”‚ - edge_count     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤1: ç”¨æˆ·è§¦å‘
```python
# src/pages/graph_page.py
def show():
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”¨ å…¨é‡æ„å»º"):
            sync_service = DataSyncService()
            result = sync_service.build_knowledge_graph(
                kb_name="policy_demo_kb",
                is_incremental=False  # å…¨é‡
            )
            st.success(f"æ„å»ºå®Œæˆï¼èŠ‚ç‚¹: {result['node_count']}, è¾¹: {result['edge_count']}")
    
    with col2:
        if st.button("âš¡ å¢é‡æ„å»º"):
            result = sync_service.build_knowledge_graph(
                kb_name="policy_demo_kb",
                is_incremental=True  # å¢é‡
            )
```

---

#### æ­¥éª¤2: è·å–æ–‡æ¡£åˆ—è¡¨
```python
# src/services/data_sync.py
def build_knowledge_graph(self, kb_name: str, is_incremental: bool = False):
    ragflow_client = get_ragflow_client()
    qwen_client = get_qwen_client()
    graph_dao = get_graph_dao()
    
    # 1. è·å–æ–‡æ¡£åˆ—è¡¨
    documents = ragflow_client.get_documents(kb_name)
    print(f"è·å–åˆ° {len(documents)} ä¸ªæ–‡æ¡£")
    
    # 2. å¦‚æœæ˜¯å¢é‡æ„å»ºï¼ŒåŠ è½½å·²æœ‰å›¾è°±
    seen_doc_names = set()
    if is_incremental:
        existing_graph = graph_dao.load_graph()
        if existing_graph:
            # æå–å·²å¤„ç†çš„æ–‡æ¡£å
            for node in existing_graph['nodes']:
                if node['type'] == 'POLICY':
                    seen_doc_names.add(node['label'])
    
    # 3. åˆå§‹åŒ–å›¾è°±æ•°æ®ç»“æ„
    all_nodes = []
    all_edges = []
    seen_node_ids = set()
```

---

#### æ­¥éª¤3: éå†æ–‡æ¡£å¹¶è°ƒç”¨Qwen
```python
    # 4. éå†æ¯ä¸ªæ–‡æ¡£
    for idx, doc in enumerate(documents):
        doc_id = doc['id']
        doc_name = doc['name'].replace('.pdf', '').replace('.docx', '')
        
        # å¢é‡æ„å»ºï¼šè·³è¿‡å·²å¤„ç†æ–‡æ¡£
        if is_incremental and doc_name in seen_doc_names:
            continue
        
        print(f"[{idx+1}/{len(documents)}] å¤„ç†æ–‡æ¡£: {doc_name}")
        
        try:
            # 5. è·å–æ–‡æ¡£å®Œæ•´å†…å®¹
            content = ragflow_client.get_document_content(doc_id, kb_name)
            
            # é™åˆ¶é•¿åº¦ï¼ˆé¿å…Qwenè¶…å‡ºtokené™åˆ¶ï¼‰
            if len(content) > 10000:
                content = content[:10000]
            
            # 6. è°ƒç”¨QwenæŠ½å–å®ä½“å’Œå…³ç³»
            extraction = qwen_client.extract_entities_and_relations(
                text=content,
                doc_title=doc_name
            )
            
            # 7. æ„å»ºèŠ‚ç‚¹
            for entity in extraction['entities']:
                node_id = f"{entity['type']}_{entity['text']}"
                
                # å»é‡
                if node_id in seen_node_ids:
                    continue
                
                seen_node_ids.add(node_id)
                
                all_nodes.append({
                    'id': node_id,
                    'label': entity['text'],
                    'type': entity['type'],
                    'description': entity.get('description', ''),
                    'source_doc': doc_name
                })
            
            # 8. æ„å»ºè¾¹
            for relation in extraction['relations']:
                source_id = f"UNKNOWN_{relation['source']}"
                target_id = f"UNKNOWN_{relation['target']}"
                
                # æŸ¥æ‰¾å®é™…çš„èŠ‚ç‚¹ID
                for node in all_nodes:
                    if node['label'] == relation['source']:
                        source_id = node['id']
                    if node['label'] == relation['target']:
                        target_id = node['id']
                
                # éªŒè¯èŠ‚ç‚¹å­˜åœ¨
                if source_id.startswith('UNKNOWN') or target_id.startswith('UNKNOWN'):
                    continue
                
                all_edges.append({
                    'from': source_id,
                    'to': target_id,
                    'type': relation['type'],
                    'source_doc': doc_name
                })
        
        except Exception as e:
            print(f"å¤„ç†æ–‡æ¡£ {doc_name} å¤±è´¥: {e}")
            continue
```

---

#### æ­¥éª¤4: Qwenæç¤ºè¯å·¥ç¨‹
```
# config/prompts/entity_extraction.txt

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ”¿ç­–æ–‡æœ¬åˆ†æä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ”¿ç­–æ–‡æœ¬ä¸­æå–å®ä½“å’Œå…³ç³»ã€‚

æ–‡æ¡£æ ‡é¢˜: {doc_title}

æ”¿ç­–æ–‡æœ¬:
{text}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœ:

{{
  "entities": [
    {{
      "text": "å®ä½“åç§°",
      "type": "POLICY | AUTHORITY | REGION | CONCEPT | PROJECT",
      "description": "ç®€çŸ­æè¿°"
    }}
  ],
  "relations": [
    {{
      "source": "æºå®ä½“åç§°ï¼ˆå¿…é¡»æ˜¯entitiesä¸­çš„textï¼‰",
      "target": "ç›®æ ‡å®ä½“åç§°ï¼ˆå¿…é¡»æ˜¯entitiesä¸­çš„textï¼‰",
      "type": "ISSUED_BY | APPLIES_TO | REFERENCES | AFFECTS | BELONGS_TO"
    }}
  ]
}}

æ³¨æ„äº‹é¡¹:
1. å®ä½“ç±»å‹:
   - POLICY: æ”¿ç­–æ–‡æ¡£æœ¬èº«
   - AUTHORITY: å‘å¸ƒæœºæ„ï¼ˆå¦‚"å¹¿ä¸œçœç§‘æŠ€å…"ï¼‰
   - REGION: åœ°åŒºï¼ˆå¦‚"å¹¿ä¸œçœ"ã€"æ·±åœ³å¸‚"ï¼‰
   - CONCEPT: æŠ½è±¡æ¦‚å¿µï¼ˆå¦‚"é«˜æ–°æŠ€æœ¯ä¼ä¸š"ã€"ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤"ï¼‰
   - PROJECT: å…·ä½“é¡¹ç›®æˆ–è®¡åˆ’

2. å…³ç³»ç±»å‹:
   - ISSUED_BY: å‘å¸ƒå…³ç³»ï¼ˆæ”¿ç­– â†’ æœºæ„ï¼‰
   - APPLIES_TO: é€‚ç”¨å…³ç³»ï¼ˆæ”¿ç­– â†’ å¯¹è±¡ï¼‰
   - REFERENCES: å¼•ç”¨å…³ç³»ï¼ˆæ”¿ç­– â†’ æ”¿ç­–ï¼‰
   - AFFECTS: å½±å“å…³ç³»ï¼ˆæ”¿ç­– â†’ æ¦‚å¿µ/é¡¹ç›®ï¼‰
   - BELONGS_TO: ä»å±å…³ç³»ï¼ˆæœºæ„ â†’ åœ°åŒºï¼‰

3. relationsä¸­çš„sourceå’Œtargetå¿…é¡»æ˜¯entitiesä¸­å‡ºç°çš„textï¼Œå®Œå…¨åŒ¹é…

4. åªè¿”å›JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—
```

---

#### æ­¥éª¤5: Qwenè¿”å›ç¤ºä¾‹
```json
{
  "entities": [
    {
      "text": "ç§‘æŠ€åˆ›æ–°æ”¿ç­–",
      "type": "POLICY",
      "description": "å¹¿ä¸œçœç§‘æŠ€åˆ›æ–°ç›¸å…³æ”¿ç­–æ–‡ä»¶"
    },
    {
      "text": "å¹¿ä¸œçœç§‘æŠ€å…",
      "type": "AUTHORITY",
      "description": "æ”¿ç­–å‘å¸ƒæœºæ„"
    },
    {
      "text": "å¹¿ä¸œçœ",
      "type": "REGION",
      "description": "æ”¿ç­–é€‚ç”¨åœ°åŒº"
    },
    {
      "text": "é«˜æ–°æŠ€æœ¯ä¼ä¸š",
      "type": "CONCEPT",
      "description": "æ”¿ç­–æ‰¶æŒå¯¹è±¡"
    },
    {
      "text": "ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤",
      "type": "CONCEPT",
      "description": "ç¨æ”¶ä¼˜æƒ æªæ–½"
    }
  ],
  "relations": [
    {
      "source": "ç§‘æŠ€åˆ›æ–°æ”¿ç­–",
      "target": "å¹¿ä¸œçœç§‘æŠ€å…",
      "type": "ISSUED_BY"
    },
    {
      "source": "ç§‘æŠ€åˆ›æ–°æ”¿ç­–",
      "target": "é«˜æ–°æŠ€æœ¯ä¼ä¸š",
      "type": "APPLIES_TO"
    },
    {
      "source": "ç§‘æŠ€åˆ›æ–°æ”¿ç­–",
      "target": "ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤",
      "type": "AFFECTS"
    },
    {
      "source": "å¹¿ä¸œçœç§‘æŠ€å…",
      "target": "å¹¿ä¸œçœ",
      "type": "BELONGS_TO"
    }
  ]
}
```

---

#### æ­¥éª¤6: ä¿å­˜å›¾è°±
```python
    # 9. ä¿å­˜åˆ°æ•°æ®åº“
    graph_data = {
        'nodes': all_nodes,
        'edges': all_edges
    }
    
    graph_dao.save_graph(graph_data, is_incremental=is_incremental)
    
    # 10. è¿”å›ç»Ÿè®¡ç»“æœ
    return {
        'node_count': len(all_nodes),
        'edge_count': len(all_edges),
        'document_count': len(documents),
        'elapsed_time': time.time() - start_time
    }
```

---

### æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | å…¨é‡æ„å»º (40æ–‡æ¡£) | å¢é‡æ„å»º (5æ–°æ–‡æ¡£) |
|------|----------------|------------------|
| æ€»è€—æ—¶ | ~145ç§’ (2.4åˆ†é’Ÿ) | ~18ç§’ |
| å•æ–‡æ¡£è€—æ—¶ | ~3.6ç§’ | ~3.6ç§’ |
| Qwenè°ƒç”¨æ¬¡æ•° | 40æ¬¡ | 5æ¬¡ |
| Tokenæ¶ˆè€— | ~120K tokens | ~15K tokens |
| æˆæœ¬ (qwen-plus) | ~ï¿¥0.48 | ~ï¿¥0.06 |
| ç”ŸæˆèŠ‚ç‚¹æ•° | 40ä¸ª | 8ä¸ª |
| ç”Ÿæˆè¾¹æ•° | 73æ¡ | 12æ¡ |

**ä¼˜åŒ–å»ºè®®**:
1. ä½¿ç”¨qwen-turboæ›¿ä»£qwen-plusï¼ˆé™ä½50%æˆæœ¬ï¼Œé€Ÿåº¦æå‡30%ï¼‰
2. é™åˆ¶æ–‡æ¡£é•¿åº¦ï¼ˆæˆªå–å‰5000å­—ï¼‰
3. æ‰¹é‡è°ƒç”¨ï¼ˆå¦‚æœQwenæ”¯æŒï¼‰
4. ç¼“å­˜å·²å¤„ç†æ–‡æ¡£çš„ç»“æœ

---

## 3ï¸âƒ£ æ™ºèƒ½é—®ç­”æµ

### å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ChatPage   â”‚ ç”¨æˆ·è¾“å…¥é—®é¢˜
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatService      â”‚
â”‚ chat(question,   â”‚
â”‚      session_id, â”‚
â”‚      stream=True)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAGFlow Chat Assistant â”‚
â”‚ POST /v1/chat          â”‚
â”‚ {                      â”‚
â”‚   "question": "...",   â”‚
â”‚   "session_id": "...", â”‚
â”‚   "stream": true       â”‚
â”‚ }                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€ â‘  å‘é‡æ£€ç´¢ (Retrieve)
       â”‚  â””â”€ æŸ¥è¯¢å‘é‡æ•°æ®åº“
       â”‚     â””â”€ è¿”å›Top-5ç›¸å…³chunks
       â”‚
       â”œâ”€ â‘¡ é‡æ’åº (Rerank)
       â”‚  â””â”€ æ ¹æ®ç›¸ä¼¼åº¦é‡æ–°æ’åº
       â”‚
       â”œâ”€ â‘¢ ç”Ÿæˆç­”æ¡ˆ (Generate)
       â”‚  â”œâ”€ æ„å»ºPrompt
       â”‚  â”‚  â”œâ”€ ç³»ç»Ÿæç¤ºè¯
       â”‚  â”‚  â”œâ”€ æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸Šä¸‹æ–‡
       â”‚  â”‚  â””â”€ ç”¨æˆ·é—®é¢˜
       â”‚  â”‚
       â”‚  â””â”€ è°ƒç”¨å¤§æ¨¡å‹ (å¦‚Qwen)
       â”‚     â””â”€ æµå¼è¿”å›ç­”æ¡ˆ
       â”‚
       â””â”€ â‘£ è¿”å›ç»“æœ
          â”œâ”€ answer (å®Œæ•´ç­”æ¡ˆ)
          â””â”€ references (å‚è€ƒæ–‡æ¡£åˆ—è¡¨)
              â””â”€ [{doc_id, doc_name, chunk_id, similarity}]
```

---

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤1: ç”¨æˆ·è¾“å…¥
```python
# src/pages/chat_page.py
def show():
    st.title("ğŸ’¬ æ™ºèƒ½é—®ç­”")
    
    # åˆå§‹åŒ–session_state
    if 'chat_messages' not in st.session_state:
        st.session_state.chat_messages = []
    
    if 'current_session_id' not in st.session_state:
        chat_service = get_chat_service()
        st.session_state.current_session_id = chat_service.create_session()
    
    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜"):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.chat_messages.append({
            "role": "user",
            "content": prompt
        })
        
        # è°ƒç”¨Chat Serviceï¼ˆæµå¼ï¼‰
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            references = []
            
            for chunk in chat_service.chat(
                question=prompt,
                session_id=st.session_state.current_session_id,
                stream=True
            ):
                if 'delta' in chunk:
                    # å¢é‡æ–‡æœ¬
                    full_response += chunk['delta']
                    message_placeholder.markdown(full_response + "â–Œ")
                elif 'answer' in chunk:
                    # æœ€åä¸€ä¸ªchunkï¼ŒåŒ…å«å®Œæ•´ç­”æ¡ˆå’Œå‚è€ƒ
                    full_response = chunk['answer']
                    references = chunk.get('references', [])
            
            message_placeholder.markdown(full_response)
            
            # æ˜¾ç¤ºå‚è€ƒæ–‡æ¡£
            if references:
                with st.expander("ğŸ“š å‚è€ƒæ–‡æ¡£"):
                    for i, ref in enumerate(references):
                        st.write(f"[{i+1}] {ref['doc_name']} (ç›¸ä¼¼åº¦: {ref['similarity']:.2f})")
        
        # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
        st.session_state.chat_messages.append({
            "role": "assistant",
            "content": full_response,
            "references": references
        })
```

---

#### æ­¥éª¤2: ChatServiceè°ƒç”¨
```python
# src/services/chat_service.py
def chat(self, question: str, session_id: str = None, stream: bool = False):
    """
    å‘é€é—®é¢˜åˆ°RAGFlow Chat Assistant
    """
    if session_id is None:
        session_id = self.create_session()
    
    # è°ƒç”¨RAGFlow Chat API
    response = requests.post(
        f"{self.api_url}/v1/chat",
        headers={
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        },
        json={
            "question": question,
            "session_id": session_id,
            "stream": stream
        },
        stream=stream  # å¯ç”¨æµå¼å“åº”
    )
    
    if stream:
        # æµå¼è¿”å›ï¼ˆç”Ÿæˆå™¨ï¼‰
        for line in response.iter_lines():
            if line:
                data = json.loads(line.decode('utf-8'))
                
                if 'delta' in data:
                    # å¢é‡æ–‡æœ¬
                    yield {"delta": data['delta']}
                elif 'answer' in data:
                    # å®Œæ•´ç­”æ¡ˆï¼ˆæœ€åä¸€ä¸ªchunkï¼‰
                    yield {
                        "answer": data['answer'],
                        "references": data.get('references', [])
                    }
    else:
        # éæµå¼è¿”å›
        result = response.json()
        return {
            "answer": result['answer'],
            "references": result.get('references', []),
            "session_id": session_id
        }
```

---

#### æ­¥éª¤3: RAGFlowå†…éƒ¨å¤„ç†

##### 3.1 å‘é‡æ£€ç´¢
```python
# RAGFlowå†…éƒ¨ï¼ˆä¸å¯è§ï¼Œä»…è¯´æ˜åŸç†ï¼‰

# 1. å°†é—®é¢˜å‘é‡åŒ–
question_embedding = embedding_model.encode(question)
# è¿”å›: [0.123, -0.456, 0.789, ...] (768ç»´å‘é‡)

# 2. å‘é‡ç›¸ä¼¼åº¦æœç´¢
results = vector_db.search(
    query_vector=question_embedding,
    top_k=10,  # åˆæ­¥æ£€ç´¢10ä¸ªå€™é€‰
    filters={
        "kb_name": "policy_demo_kb"
    }
)

# 3. è¿”å›å€™é€‰chunks
# [
#   {"chunk_id": "chunk_123", "doc_id": "doc_1", "similarity": 0.92, "content": "..."},
#   {"chunk_id": "chunk_456", "doc_id": "doc_2", "similarity": 0.87, "content": "..."},
#   ...
# ]
```

##### 3.2 é‡æ’åºï¼ˆå¯é€‰ï¼‰
```python
# ä½¿ç”¨é‡æ’åºæ¨¡å‹ï¼ˆå¦‚BGE Rerankerï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–ç»“æœ
reranked_results = reranker.rank(
    query=question,
    documents=[r['content'] for r in results]
)

# å–Top-5ä½œä¸ºæœ€ç»ˆä¸Šä¸‹æ–‡
final_docs = reranked_results[:5]
```

##### 3.3 æ„å»ºPrompt
```python
# ç³»ç»Ÿæç¤ºè¯
system_prompt = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ”¿ç­–å’¨è¯¢åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹å‚è€ƒæ–‡æ¡£å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœå‚è€ƒæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ã€‚
å›ç­”è¦å‡†ç¡®ã€å…¨é¢ã€æ˜“æ‡‚ã€‚
"""

# æ‹¼æ¥å‚è€ƒæ–‡æ¡£
context = ""
for i, doc in enumerate(final_docs):
    context += f"\n[å‚è€ƒæ–‡æ¡£{i+1}] {doc['doc_name']}\n{doc['content']}\n"

# å®Œæ•´Prompt
full_prompt = f"""
{system_prompt}

{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·å›ç­”:
"""
```

##### 3.4 è°ƒç”¨å¤§æ¨¡å‹ï¼ˆæµå¼ï¼‰
```python
# è°ƒç”¨Qwenæˆ–å…¶ä»–å¤§æ¨¡å‹
for chunk in llm.generate_stream(full_prompt):
    yield {
        "delta": chunk.text,  # å¢é‡æ–‡æœ¬
        "finish_reason": chunk.finish_reason
    }

# æœ€åä¸€ä¸ªchunkè¿”å›å®Œæ•´ç­”æ¡ˆå’Œå‚è€ƒ
yield {
    "answer": full_answer,
    "references": [
        {
            "doc_id": doc['doc_id'],
            "doc_name": doc['doc_name'],
            "chunk_id": doc['chunk_id'],
            "similarity": doc['similarity']
        }
        for doc in final_docs
    ]
}
```

---

### ç¤ºä¾‹å¯¹è¯

**ç”¨æˆ·é—®é¢˜**: é«˜æ–°æŠ€æœ¯ä¼ä¸šæœ‰å“ªäº›ç¨æ”¶ä¼˜æƒ ï¼Ÿ

**æ£€ç´¢ç»“æœ**:
```python
[
    {
        "doc_name": "é«˜æ–°æŠ€æœ¯ä¼ä¸šç¨æ”¶æ”¿ç­–.pdf",
        "chunk_id": "chunk_12",
        "content": "é«˜æ–°æŠ€æœ¯ä¼ä¸šå‡æŒ‰15%çš„ç¨ç‡å¾æ”¶ä¼ä¸šæ‰€å¾—ç¨...",
        "similarity": 0.94
    },
    {
        "doc_name": "ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æŒ‡å—.pdf",
        "chunk_id": "chunk_7",
        "content": "é«˜æ–°æŠ€æœ¯ä¼ä¸šç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ¯”ä¾‹ä¸º100%...",
        "similarity": 0.89
    }
]
```

**ç”Ÿæˆç­”æ¡ˆ**:
```
æ ¹æ®ç›¸å…³æ”¿ç­–ï¼Œé«˜æ–°æŠ€æœ¯ä¼ä¸šå¯äº«å—ä»¥ä¸‹ç¨æ”¶ä¼˜æƒ ï¼š

1. **ä¼ä¸šæ‰€å¾—ç¨ä¼˜æƒ **
   - å‡æŒ‰15%çš„ç¨ç‡å¾æ”¶ä¼ä¸šæ‰€å¾—ç¨ï¼ˆä¸€èˆ¬ä¼ä¸šä¸º25%ï¼‰
   - é¢„è®¡å‡ç¨å¹…åº¦çº¦40%

2. **ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤**
   - ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æ¯”ä¾‹ä¸º100%
   - å³å®é™…å‘ç”Ÿ100ä¸‡å…ƒç ”å‘è´¹ç”¨ï¼Œå¯åœ¨ç¨å‰æ‰£é™¤200ä¸‡å…ƒ

3. **å…¶ä»–ä¼˜æƒ **
   - æŠ€æœ¯è½¬è®©æ‰€å¾—å…å¾ã€å‡å¾ä¼ä¸šæ‰€å¾—ç¨
   - ç¬¦åˆæ¡ä»¶çš„è½¯ä»¶ä¼ä¸š"ä¸¤å…ä¸‰å‡åŠ"

ğŸ“š å‚è€ƒæ–‡æ¡£:
[1] é«˜æ–°æŠ€æœ¯ä¼ä¸šç¨æ”¶æ”¿ç­–.pdf
[2] ç ”å‘è´¹ç”¨åŠ è®¡æ‰£é™¤æŒ‡å—.pdf
```

---

### å»é‡å‚è€ƒæ–‡æ¡£

```python
# src/pages/chat_page.py
def deduplicate_references(references: List[Dict]) -> List[Dict]:
    """
    å»é™¤é‡å¤çš„å‚è€ƒæ–‡æ¡£
    
    å»é‡è§„åˆ™:
    1. ç›¸åŒdoc_idåªä¿ç•™ç¬¬ä¸€ä¸ª
    2. æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
    """
    seen_doc_ids = set()
    unique_refs = []
    
    # å…ˆæŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
    sorted_refs = sorted(references, key=lambda x: x.get('similarity', 0), reverse=True)
    
    for ref in sorted_refs:
        doc_id = ref.get('doc_id')
        if doc_id not in seen_doc_ids:
            seen_doc_ids.add(doc_id)
            unique_refs.append(ref)
    
    return unique_refs

# ä½¿ç”¨
references = deduplicate_references(raw_references)
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [02-ARCHITECTURE.md](../02-ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„
- [modules-inventory.md](modules-inventory.md) - æ¨¡å—æ¸…å•
- [05-API_REFERENCE.md](../05-API_REFERENCE.md) - APIå‚è€ƒ

---

**Last Updated**: 2026-02-01
