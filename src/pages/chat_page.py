"""
æ™ºèƒ½é—®ç­”é¡µé¢
===========

åŸºäºRAGFlow Chat Assistant + çŸ¥è¯†å›¾è°±çš„æ™ºèƒ½å¯¹è¯ç•Œé¢

åŠŸèƒ½ç‰¹æ€§ï¼š
- æµå¼æ‰“å­—æ•ˆæœ
- å‚è€ƒæ–‡æ¡£å±•ç¤ºï¼ˆå»é‡ï¼‰
- å¯ç‚¹å‡»çš„å¼•ç”¨ç¼–å·
- çŸ¥è¯†å›¾è°±å¯è§†åŒ–
- å¤šè½®å¯¹è¯æ”¯æŒ
- ä¼šè¯ç®¡ç†
"""
import streamlit as st
import logging
import re
import hashlib

from src.services.chat_service import get_chat_service
from src.components.graph_ui import render_network_graph

logger = logging.getLogger(__name__)


def format_references_with_anchors(text: str, references: list) -> str:
    """
    å°†[ID:x]æ ‡è®°è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„å¼•ç”¨ç¼–å·
    
    Args:
        text: åŸå§‹æ–‡æœ¬ï¼ˆåŒ…å«[ID:x]æ ‡è®°ï¼‰
        references: å‚è€ƒæ–‡æ¡£åˆ—è¡¨
    
    Returns:
        æ ¼å¼åŒ–åçš„HTMLæ–‡æœ¬
    """
    if not text or not references:
        return text
    
    # å…ˆå»é‡referencesï¼Œæ„å»ºIDæ˜ å°„
    id_to_index = {}
    seen_chunks = set()
    current_index = 1
    
    for idx, ref in enumerate(references):
        chunk_id = ref.get('chunk_id', '')
        content = ref.get('content', '')
        
        # ç”Ÿæˆå”¯ä¸€æ ‡è¯†
        unique_id = chunk_id or hashlib.md5(content.encode()).hexdigest()[:16]
        
        if unique_id not in seen_chunks:
            seen_chunks.add(unique_id)
            # åŸå§‹IDå°±æ˜¯ç´¢å¼•idx
            id_to_index[str(idx)] = current_index
            current_index += 1
    
    # æ›¿æ¢[ID:x]ä¸ºå¯ç‚¹å‡»çš„å¼•ç”¨ç¼–å·
    def replace_id(match):
        id_str = match.group(1)
        display_index = id_to_index.get(id_str, int(id_str) + 1)  # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œé»˜è®¤ä½¿ç”¨åŸID+1
        return f'<a href="#ref-{display_index}" style="color: #1f77b4; text-decoration: none; font-size: 0.9em; vertical-align: super;">[{display_index}]</a>'
    
    # æ‰¾åˆ°æ‰€æœ‰[ID:x]æ ‡è®°å¹¶æ›¿æ¢
    formatted_text = re.sub(r'\[ID:(\d+)\]', replace_id, text)
    
    return formatted_text


def deduplicate_references(references: list) -> list:
    """
    å»é‡å‚è€ƒæ–‡æ¡£ï¼ˆæŒ‰æ–‡æ¡£åå»é‡ï¼‰
    
    Args:
        references: åŸå§‹å‚è€ƒæ–‡æ¡£åˆ—è¡¨
    
    Returns:
        å»é‡åçš„å‚è€ƒæ–‡æ¡£åˆ—è¡¨ï¼ˆä¿ç•™åŸå§‹IDï¼‰
    """
    seen_docs = set()
    deduplicated = []
    
    for idx, ref in enumerate(references):
        doc_name = ref.get('document_name', 'æœªçŸ¥æ–‡æ¡£')
        
        # æŒ‰æ–‡æ¡£åå»é‡
        if doc_name not in seen_docs:
            seen_docs.add(doc_name)
            # ä¿ç•™åŸå§‹IDç”¨äºæ˜ å°„
            ref['original_id'] = idx
            deduplicated.append(ref)
    
    return deduplicated


def show():
    """æ¸²æŸ“èŠå¤©é¡µé¢"""
    
    st.title("ğŸ’¬ æ™ºèƒ½é—®ç­”")
    st.caption("åŸºäºRAGFlowå‘é‡æ£€ç´¢ + çŸ¥è¯†å›¾è°±çš„æ”¿ç­–æ™ºèƒ½å’¨è¯¢")
    
    # ===== åˆå§‹åŒ–Session State =====
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'chat_session_id' not in st.session_state:
        st.session_state.chat_session_id = None
    
    # ===== é¡¶éƒ¨æ§åˆ¶æ  =====
    col1, col2, col3 = st.columns([8, 1, 1])
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤", help="æ¸…é™¤èŠå¤©å†å²å’Œä¼šè¯", use_container_width=True):
            # æ¸…é™¤åç«¯session
            if st.session_state.chat_session_id:
                try:
                    chat_service = get_chat_service()
                    chat_service.clear_session(st.session_state.chat_session_id)
                except Exception as e:
                    logger.warning(f"æ¸…é™¤ä¼šè¯å¤±è´¥: {e}")
            
            # æ¸…é™¤å‰ç«¯çŠ¶æ€
            st.session_state.chat_history = []
            st.session_state.chat_session_id = None
            st.rerun()
    
    with col3:
        # æ˜¾ç¤ºä¼šè¯çŠ¶æ€
        if st.session_state.chat_session_id:
            st.caption(f"ğŸŸ¢ ä¼šè¯ä¸­")
        else:
            st.caption("ğŸ”´ æ–°ä¼šè¯")
    
    # ===== åˆ†éš”çº¿ =====
    st.divider()
    
    # ===== æ˜¾ç¤ºèŠå¤©å†å² =====
    for idx, msg in enumerate(st.session_state.chat_history):
        with st.chat_message(msg['role']):
            # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹ï¼ˆå¸¦å¼•ç”¨ç¼–å·ï¼‰
            if msg['role'] == 'assistant' and msg.get('references'):
                # æ ¼å¼åŒ–ç­”æ¡ˆï¼Œå°†[ID:x]è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„å¼•ç”¨
                formatted_content = format_references_with_anchors(
                    msg['content'], 
                    msg['references']
                )
                st.markdown(formatted_content, unsafe_allow_html=True)
            else:
                st.markdown(msg['content'])
            
            # æ˜¾ç¤ºå‚è€ƒæ–‡æ¡£ï¼ˆRAGFlowåŸç”Ÿé£æ ¼ï¼‰
            if msg.get('references') and len(msg['references']) > 0:
                references = msg['references']
                
                # æŒ‰æ–‡æ¡£åˆ†ç»„ç»Ÿè®¡
                doc_groups = {}
                for ref in references:
                    doc_name = ref.get('document_name', 'Unknown')
                    if doc_name not in doc_groups:
                        doc_groups[doc_name] = {
                            'count': 0,
                            'chunks': [],
                            'doc_id': ref.get('document_id', ''),
                            'dataset_id': ref.get('dataset_id', '')
                        }
                    doc_groups[doc_name]['count'] += 1
                    doc_groups[doc_name]['chunks'].append(ref)
                
                with st.expander(
                    f"ğŸ“š å‚è€ƒæ–‡æ¡£ ({len(doc_groups)}ä¸ªæ–‡æ¡£, {len(references)}ä¸ªå¼•ç”¨ç‰‡æ®µ)", 
                    expanded=False
                ):
                    # æ˜¾ç¤ºæ¯ä¸ªchunkï¼ˆç±»ä¼¼RAGFlowï¼‰
                    for i, ref in enumerate(references, 1):
                        doc_name = ref.get('document_name', 'Unknown')
                        doc_id = ref.get('document_id', '')
                        dataset_id = ref.get('dataset_id', '')
                        similarity = ref.get('similarity', 0)
                        chunk_id = ref.get('id', '')
                        image_id = ref.get('image_id', '')
                        
                        col1, col2 = st.columns([5, 1])
                        with col1:
                            st.markdown(f"**å¼•ç”¨ #{i}: {doc_name}**")
                            st.caption(f"ç›¸ä¼¼åº¦: {similarity:.2%} | ID: {chunk_id[:12]}...")
                        
                        with col2:
                            # ä¸‹è½½æŒ‰é’®ï¼ˆè·å–å®Œæ•´æ–‡æ¡£ï¼‰
                            if st.button("ğŸ“¥", key=f"download_doc_{chunk_id}", 
                                       help="ä¸‹è½½å®Œæ•´æ–‡æ¡£"):
                                try:
                                    from src.clients.ragflow_client import RAGFlowClient
                                    ragflow = RAGFlowClient()
                                    
                                    # é€šè¿‡datasetæŸ¥æ‰¾æ–‡æ¡£å¹¶ä¸‹è½½
                                    datasets = ragflow.rag.list_datasets(id=dataset_id)
                                    if datasets:
                                        docs = datasets[0].list_documents(id=doc_id)
                                        if docs:
                                            content = docs[0].download()
                                            st.download_button(
                                                label="ğŸ’¾ ä¿å­˜",
                                                data=content,
                                                file_name=doc_name,
                                                mime="application/octet-stream",
                                                key=f"save_{chunk_id}"
                                            )
                                        else:
                                            st.error("æ–‡æ¡£æœªæ‰¾åˆ°")
                                    else:
                                        st.error("çŸ¥è¯†åº“æœªæ‰¾åˆ°")
                                except Exception as e:
                                    st.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
                        
                        # æ˜¾ç¤ºchunkå†…å®¹ï¼ˆå¯æŠ˜å ï¼‰
                        with st.expander("æŸ¥çœ‹å¼•ç”¨å†…å®¹", expanded=False):
                            st.markdown(ref.get('content', ''))
                            
                            # å¦‚æœæœ‰å›¾ç‰‡æˆªå›¾
                            if image_id:
                                st.caption(f"ğŸ“¸ åŒ…å«å›¾ç‰‡æˆªå›¾ (ID: {image_id})")
                        
                        if i < len(references):
                            st.divider()
            
            # æ˜¾ç¤ºçŸ¥è¯†å›¾è°±ï¼ˆæŠ˜å ï¼‰
            if msg.get('graph_context'):
                graph_context = msg['graph_context']
                subgraph = graph_context.get('subgraph')
                
                if subgraph and subgraph.get_node_count() > 0:
                    relations = graph_context.get('relations', [])
                    node_count = subgraph.get_node_count()
                    
                    with st.expander(
                        f"ğŸ”— çŸ¥è¯†å›¾è°± ({node_count}ä¸ªèŠ‚ç‚¹, {len(relations)}æ¡å…³ç³»)", 
                        expanded=False
                    ):
                        # æ˜¾ç¤ºå…³ç³»åˆ—è¡¨
                        if relations:
                            st.caption("**ç›¸å…³å…³ç³»**:")
                            for r in relations[:8]:  # åªæ˜¾ç¤ºå‰8æ¡
                                st.markdown(
                                    f"â€¢ {r['source']} â†’ *{r['relation']}* â†’ {r['target']}"
                                )
                            
                            if len(relations) > 8:
                                st.caption(f"...è¿˜æœ‰ {len(relations) - 8} æ¡å…³ç³»")
                            
                            st.divider()
                        
                        # å¯è§†åŒ–å›¾è°±
                        st.caption("**å›¾è°±å¯è§†åŒ–**:")
                        try:
                            nx_graph = subgraph.get_nx_graph()
                            render_network_graph(nx_graph)
                        except Exception as e:
                            st.error(f"å›¾è°±å¯è§†åŒ–å¤±è´¥: {e}")
    
    # ===== èŠå¤©è¾“å…¥æ¡† =====
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...", key="chat_input"):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.chat_history.append({
            'role': 'user',
            'content': prompt
        })
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ===== è°ƒç”¨ChatServiceï¼Œæµå¼æ˜¾ç¤ºå›ç­” =====
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            references = []
            graph_context = None
            session_id = st.session_state.chat_session_id
            
            try:
                chat_service = get_chat_service()
                
                # æµå¼å¤„ç†å“åº”
                for chunk in chat_service.chat(
                    question=prompt, 
                    session_id=session_id, 
                    stream=True
                ):
                    if chunk['type'] == 'chunk':
                        # æ–‡æœ¬chunk - RAGFlowè¿”å›çš„æ˜¯ç´¯ç§¯å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨
                        full_response = chunk['content']
                        message_placeholder.markdown(full_response + "â–Œ")
                    
                    elif chunk['type'] == 'reference':
                        # å‚è€ƒæ–‡æ¡£
                        references = chunk['docs']
                    
                    elif chunk['type'] == 'graph':
                        # å›¾è°±ä¸Šä¸‹æ–‡
                        graph_context = chunk['context']
                        session_id = chunk.get('session_id')
                        
                        # æ›´æ–°session_id
                        if session_id:
                            st.session_state.chat_session_id = session_id
                    
                    elif chunk['type'] == 'error':
                        # é”™è¯¯ä¿¡æ¯
                        st.error(f"âš ï¸ {chunk['message']}")
                        full_response = f"æŠ±æ­‰ï¼Œå‡ºç°é”™è¯¯ï¼š{chunk['message']}"
                        break
                
                # å®Œæˆæ‰“å­—æ•ˆæœï¼Œæ˜¾ç¤ºå¸¦å¼•ç”¨çš„æœ€ç»ˆç­”æ¡ˆ
                if references:
                    formatted_response = format_references_with_anchors(full_response, references)
                    message_placeholder.markdown(formatted_response, unsafe_allow_html=True)
                else:
                    message_placeholder.markdown(full_response)
                
                # ===== æ˜¾ç¤ºå‚è€ƒæ–‡æ¡£ï¼ˆå»é‡ï¼‰ =====
                if references and len(references) > 0:
                    dedup_refs = deduplicate_references(references)
                    
                    with st.expander(f"ğŸ“š å‚è€ƒæ–‡æ¡£ ({len(dedup_refs)}ä¸ª)", expanded=False):
                        for i, ref in enumerate(dedup_refs, 1):
                            # æ·»åŠ é”šç‚¹ä¾›å¼•ç”¨ç¼–å·è·³è½¬
                            st.markdown(f'<div id="ref-{i}"></div>', unsafe_allow_html=True)
                            
                            st.markdown(f"**[{i}] {ref['document_name']}**")
                            st.caption(f"ç›¸ä¼¼åº¦: {ref['similarity']:.2%}")
                            
                            content = ref['content']
                            if len(content) > 300:
                                st.text(content[:300] + "...")
                            else:
                                st.text(content)
                            
                            if i < len(dedup_refs):
                                st.divider()
                
                # ===== æ˜¾ç¤ºçŸ¥è¯†å›¾è°± =====
                if graph_context and graph_context.get('subgraph'):
                    subgraph = graph_context['subgraph']
                    
                    if subgraph and subgraph.get_node_count() > 0:
                        relations = graph_context.get('relations', [])
                        node_count = subgraph.get_node_count()
                        
                        with st.expander(
                            f"ğŸ”— çŸ¥è¯†å›¾è°± ({node_count}ä¸ªèŠ‚ç‚¹, {len(relations)}æ¡å…³ç³»)", 
                            expanded=False
                        ):
                            # æ˜¾ç¤ºå…³ç³»åˆ—è¡¨
                            if relations:
                                st.caption("**ç›¸å…³å…³ç³»**:")
                                for r in relations[:8]:
                                    st.markdown(
                                        f"â€¢ {r['source']} â†’ *{r['relation']}* â†’ {r['target']}"
                                    )
                                
                                if len(relations) > 8:
                                    st.caption(f"...è¿˜æœ‰ {len(relations) - 8} æ¡å…³ç³»")
                                
                                st.divider()
                            
                            # å¯è§†åŒ–å›¾è°±
                            st.caption("**å›¾è°±å¯è§†åŒ–**:")
                            try:
                                nx_graph = subgraph.get_nx_graph()
                                render_network_graph(nx_graph)
                            except Exception as e:
                                st.error(f"å›¾è°±å¯è§†åŒ–å¤±è´¥: {e}")
            
            except Exception as e:
                st.error(f"âš ï¸ å¯¹è¯å¤±è´¥: {str(e)}")
                logger.error(f"å¯¹è¯å¤±è´¥: {e}", exc_info=True)
                full_response = "æŠ±æ­‰ï¼Œç³»ç»Ÿå‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚"
        
        # ===== ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å² =====
        st.session_state.chat_history.append({
            'role': 'assistant',
            'content': full_response,
            'references': references,
            'graph_context': graph_context
        })
    
    # ===== é¡µé¢åº•éƒ¨æç¤º =====
    if len(st.session_state.chat_history) == 0:
        st.info(
            "ğŸ’¡ **ä½¿ç”¨æç¤º**\n\n"
            "â€¢ è¾“å…¥æ”¿ç­–ç›¸å…³é—®é¢˜ï¼Œç³»ç»Ÿä¼šç»“åˆæ–‡æ¡£å’ŒçŸ¥è¯†å›¾è°±ä¸ºæ‚¨è§£ç­”\n"
            "â€¢ ç­”æ¡ˆä¸­çš„è“è‰²æ•°å­— [1,2] å¯ç‚¹å‡»è·³è½¬åˆ°å¯¹åº”å‚è€ƒæ–‡æ¡£\n"
            "â€¢ ç‚¹å‡»æŠ˜å é¢æ¿å¯æŸ¥çœ‹å‚è€ƒæ–‡æ¡£å’ŒçŸ¥è¯†å›¾è°±\n"
            "â€¢ æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä¸Šä¸‹æ–‡ä¼šè‡ªåŠ¨ä¿æŒ\n"
            "â€¢ ç‚¹å‡»ã€Œæ¸…é™¤ã€æŒ‰é’®å¯å¼€å§‹æ–°å¯¹è¯"
        )


if __name__ == "__main__":
    show()
