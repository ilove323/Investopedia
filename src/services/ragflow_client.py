"""
RAGFlowæœåŠ¡å®¢æˆ·ç«¯
=================
è´Ÿè´£ä¸RAGFlowæœåŠ¡çš„APIäº¤äº’ã€‚

æ ¸å¿ƒåŠŸèƒ½ï¼š
- å¥åº·æ£€æŸ¥ï¼ˆéªŒè¯æœåŠ¡è¿æ¥ï¼‰
- æ–‡æ¡£ä¸Šä¼ ï¼ˆå‘RAGFlowä¸Šä¼ æ”¿ç­–æ–‡æ¡£ï¼‰
- æ–‡æ¡£åˆ é™¤ï¼ˆä»RAGFlowåˆ é™¤æ–‡æ¡£ï¼‰
- è¯­ä¹‰æœç´¢ï¼ˆåŸºäºå‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼‰
- é—®ç­”åŠŸèƒ½ï¼ˆè°ƒç”¨RAGFlowçš„é—®ç­”APIï¼‰
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

ä¾èµ–ï¼š
- src.config.ConfigLoader - RAGFlowæœåŠ¡é…ç½®
- src.services.api_utils - HTTPè¯·æ±‚å·¥å…·

é…ç½®é¡¹ï¼ˆæ¥è‡ªconfig.iniçš„[RAGFLOW]éƒ¨åˆ†ï¼‰ï¼š
- host: RAGFlowæœåŠ¡ä¸»æœºåœ°å€
- port: RAGFlowæœåŠ¡ç«¯å£
- timeout: APIè°ƒç”¨è¶…æ—¶æ—¶é—´
- retry_times: é‡è¯•æ¬¡æ•°
- retry_delay: é‡è¯•å»¶è¿Ÿ

ä½¿ç”¨ç¤ºä¾‹ï¼š
    from src.services.ragflow_client import get_ragflow_client

    client = get_ragflow_client()

    # æ£€æŸ¥è¿æ¥
    if client.check_health():
        print("RAGFlowæœåŠ¡æ­£å¸¸")

    # ä¸Šä¼ æ–‡æ¡£
    doc_id = client.upload_document("policy.pdf", content)

    # æœç´¢
    results = client.search("æ”¿ç­–å†…å®¹", top_k=10)
"""
import logging
import requests
from typing import Optional, Dict, List, Any

# ===== å¯¼å…¥æ–°çš„é…ç½®ç³»ç»Ÿ =====
from src.config import get_config
from src.services.api_utils import APIClient, APIError

# ===== è·å–RAGFlowé…ç½® =====
config = get_config()

RAGFLOW_BASE_URL = config.ragflow_base_url  # RAGFlowæœåŠ¡URLï¼ˆhttp://host:portï¼‰
RAGFLOW_API_KEY = config.ragflow_api_key  # RAGFlow APIå¯†é’¥ï¼ˆå¦‚æœéœ€è¦è®¤è¯ï¼‰
RAGFLOW_TIMEOUT = config.ragflow_timeout  # APIè°ƒç”¨è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
RAGFLOW_RETRY_TIMES = config.ragflow_retry_times  # å¤±è´¥é‡è¯•æ¬¡æ•°
RAGFLOW_RETRY_DELAY = config.ragflow_retry_delay  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
RAGFLOW_SEARCH_CONFIG = config.ragflow_search_config  # æœç´¢é…ç½®ï¼ˆtop_k, thresholdç­‰ï¼‰
RAGFLOW_QA_CONFIG = config.ragflow_qa_config  # é—®ç­”é…ç½®ï¼ˆmax_tokens, temperatureç­‰ï¼‰

# RAGFlow APIç«¯ç‚¹å®šä¹‰
RAGFLOW_ENDPOINTS = {
    'health': '/api/health',
    'upload': '/api/upload',
    'delete': '/api/delete',
    'search': '/api/search',
    'qa': '/api/qa',
    'documents': '/api/v1/datasets/{dataset_id}/documents',  # æ–‡æ¡£åˆ—è¡¨ - æ­£ç¡®çš„ç«¯ç‚¹
    'datasets': '/api/v1/datasets',  # çŸ¥è¯†åº“åˆ—è¡¨ - æ­£ç¡®çš„ç«¯ç‚¹
    'retrieval': '/api/v1/retrieval'  # æ£€ç´¢ç«¯ç‚¹ - æ­£ç¡®çš„ç«¯ç‚¹
}

# RAGFlow APIè¯·æ±‚å¤´ï¼ˆåŒ…å«è®¤è¯ä¿¡æ¯ï¼‰
def _get_ragflow_headers() -> dict:
    """
    ç”ŸæˆRAGFlowè¯·æ±‚å¤´ï¼ŒåŒ…å«API Keyè®¤è¯ä¿¡æ¯

    å¦‚æœé…ç½®äº†RAGFLOW_API_KEYï¼Œå°†é€šè¿‡Authorizationå¤´å‘é€
    æ ¼å¼ï¼šAuthorization: Bearer {api_key}
    """
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }

    # å¦‚æœé…ç½®äº†API Keyï¼Œæ·»åŠ è®¤è¯ä¿¡æ¯
    if RAGFLOW_API_KEY:
        headers['Authorization'] = f'Bearer {RAGFLOW_API_KEY}'

    return headers

logger = logging.getLogger(__name__)


class RAGFlowError(APIError):
    """RAGFlow APIé”™è¯¯"""
    pass


class RAGFlowClient:
    """RAGFlowå®¢æˆ·ç«¯"""

    def __init__(self, auto_configure: bool = True):
        """åˆå§‹åŒ–RAGFlowå®¢æˆ·ç«¯
        
        Args:
            auto_configure: æ˜¯å¦åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨åº”ç”¨é…ç½®å‚æ•°
        """
        self.client = APIClient(
            base_url=RAGFLOW_BASE_URL,
            timeout=RAGFLOW_TIMEOUT,
            retry_times=RAGFLOW_RETRY_TIMES
        )
        # ç”ŸæˆåŒ…å«è®¤è¯ä¿¡æ¯çš„è¯·æ±‚å¤´
        self.headers = _get_ragflow_headers()

        # å¦‚æœé…ç½®äº†API Keyï¼Œè®°å½•æ—¥å¿—
        if RAGFLOW_API_KEY:
            logger.info("RAGFlowå®¢æˆ·ç«¯: ä½¿ç”¨API Keyè®¤è¯")

        self._check_connection()
        
        # è‡ªåŠ¨åº”ç”¨é…ç½®å‚æ•°
        if auto_configure:
            self._apply_configuration()

    def _check_connection(self):
        """æ£€æŸ¥ä¸RAGFlowçš„è¿æ¥"""
        try:
            # å°è¯•è¿æ¥åˆ°åŸºç¡€ URLï¼Œæ£€æŸ¥æœåŠ¡æ˜¯å¦åœ¨çº¿
            # æ³¨ï¼šä¸åŒç‰ˆæœ¬çš„ RAGFlow å¯èƒ½æœ‰ä¸åŒçš„ API è·¯å¾„
            response = requests.get(RAGFLOW_BASE_URL, timeout=5)
            # åªè¦èƒ½è¿æ¥ä¸ŠæœåŠ¡ï¼Œå°±è®¤ä¸ºå¯ç”¨ï¼ˆå³ä½¿è¿”å› 404ï¼‰
            logger.info(f"RAGFlowæœåŠ¡è¿æ¥æˆåŠŸ (HTTP {response.status_code})")
        except requests.exceptions.ConnectionError:
            logger.warning(f"RAGFlowæœåŠ¡ç¦»çº¿æˆ–åœ°å€é”™è¯¯: {RAGFLOW_BASE_URL}")
        except requests.exceptions.Timeout:
            logger.warning(f"RAGFlowæœåŠ¡è¿æ¥è¶…æ—¶")
        except Exception as e:
            logger.warning(f"RAGFlowæœåŠ¡è¿æ¥æ£€æŸ¥å¤±è´¥: {e}")

    def _apply_configuration(self):
        """åº”ç”¨é…ç½®æ–‡ä»¶ä¸­çš„RAGFlowå‚æ•°"""
        try:
            from src.config import get_config
            
            config = get_config()
            
            # è·å–é»˜è®¤çŸ¥è¯†åº“é…ç½®
            kb_name = config.default_kb_name
            kb_config = config.get_kb_config(kb_name)
            
            if not kb_config:
                logger.warning(f"âš ï¸ æ— æ³•åŠ è½½çŸ¥è¯†åº“ '{kb_name}' çš„é…ç½®")
                return
            
            logger.info(f"å¼€å§‹åº”ç”¨çŸ¥è¯†åº“ '{kb_name}' çš„é…ç½®...")
            
            # 1. é¦–å…ˆæ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
            if not self._check_knowledge_base_exists(kb_config['kb_name']):
                logger.warning(f"âš ï¸ çŸ¥è¯†åº“ '{kb_config['kb_name']}' ä¸å­˜åœ¨")
                logger.info(f"ğŸ’¡ è¯·åœ¨RAGFlow Webç•Œé¢ ({RAGFLOW_BASE_URL}) ä¸­åˆ›å»ºçŸ¥è¯†åº“")
                logger.warning("RAGFlowé…ç½®å¯èƒ½æœªå®Œå…¨ç”Ÿæ•ˆ")
                return
            
            logger.info(f"ğŸ“‹ åº”ç”¨é…ç½®: {len(kb_config)} ä¸ªå‚æ•°")
            
            # 2. åº”ç”¨çŸ¥è¯†åº“é…ç½®
            success = self._update_knowledge_base_config(kb_config['kb_name'], kb_config)
            
            if success:
                logger.info("âœ… çŸ¥è¯†åº“é…ç½®åº”ç”¨æˆåŠŸ")
                logger.info(f"ğŸ›ï¸ é…ç½®è¯¦æƒ…: åˆ†å—å¤§å°={kb_config.get('chunk_size')}, "
                          f"ç›¸ä¼¼åº¦é˜ˆå€¼={kb_config.get('similarity_threshold')}, "
                          f"å›¾è°±æ£€ç´¢={kb_config.get('graph_retrieval')}")
            else:
                logger.warning("âš ï¸ çŸ¥è¯†åº“é…ç½®å¯èƒ½æœªå®Œå…¨ç”Ÿæ•ˆ")
                
        except Exception as e:
            logger.warning(f"è‡ªåŠ¨é…ç½®å¤±è´¥: {e}")
            logger.warning("RAGFlowé…ç½®å¯èƒ½æœªå®Œå…¨ç”Ÿæ•ˆ")

    def _check_knowledge_base_exists(self, kb_name: str) -> bool:
        """
        æ£€æŸ¥çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            
        Returns:
            bool: çŸ¥è¯†åº“æ˜¯å¦å­˜åœ¨
        """
        try:
            # ä½¿ç”¨æ­£ç¡®çš„APIç«¯ç‚¹è·å–çŸ¥è¯†åº“åˆ—è¡¨
            endpoint = "/api/v1/datasets"
            
            response = self.client.get(endpoint, headers=self.headers)
            
            if isinstance(response, dict) and response.get('code') == 0:
                datasets = response.get('data', [])
                if isinstance(datasets, list):
                    # æ£€æŸ¥çŸ¥è¯†åº“åç§°åŒ¹é…
                    kb_names = []
                    kb_ids = []
                    
                    for dataset in datasets:
                        name = dataset.get('name', '')
                        id_val = dataset.get('id', '')
                        kb_names.append(name)
                        kb_ids.append(id_val)
                        
                        # æ£€æŸ¥åç§°åŒ¹é…ï¼ˆæ”¯æŒåç§°æˆ–IDåŒ¹é…ï¼‰
                        if name == kb_name or id_val == kb_name:
                            logger.info(f"âœ… çŸ¥è¯†åº“ '{kb_name}' å­˜åœ¨")
                            logger.debug(f"çŸ¥è¯†åº“è¯¦æƒ…: {dataset}")
                            return True
                    
                    logger.info(f"ğŸ“‹ å¯ç”¨çŸ¥è¯†åº“: {kb_names}")
                    logger.warning(f"âŒ çŸ¥è¯†åº“ '{kb_name}' ä¸å­˜åœ¨")
                    return False
                    
            logger.warning(f"âŒ è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {response}")
            return False
            
        except Exception as e:
            logger.warning(f"çŸ¥è¯†åº“å­˜åœ¨æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
            logger.warning("RAGFlowé…ç½®å¯èƒ½æœªå®Œå…¨ç”Ÿæ•ˆ")
    
    def _update_knowledge_base_config(self, kb_name: str, config_params: dict) -> bool:
        """æ›´æ–°çŸ¥è¯†åº“é…ç½®
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            config_params: é…ç½®å‚æ•°å­—å…¸
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.debug(f"å¼€å§‹æ›´æ–°çŸ¥è¯†åº“ '{kb_name}' çš„é…ç½®...")
            
            # é¦–å…ˆè·å–çŸ¥è¯†åº“ID
            kb_id = self._get_knowledge_base_id(kb_name)
            if not kb_id:
                logger.error(f"æ— æ³•è·å–çŸ¥è¯†åº“ '{kb_name}' çš„ID")
                return False
            
            # æ ¹æ®å®˜æ–¹APIæ–‡æ¡£æ„å»ºæ­£ç¡®çš„æ›´æ–°è¯·æ±‚
            endpoint = f"/api/v1/datasets/{kb_id}"
            
            # æ„å»ºç¬¦åˆAPIæ–‡æ¡£çš„é…ç½®æ•°æ®
            update_data = self._build_dataset_update_payload(config_params)
            
            logger.debug(f"æ›´æ–°æ•°æ®: {update_data}")
            logger.info(f"å‘ç«¯ç‚¹ {endpoint} å‘é€é…ç½®æ›´æ–°...")
            
            # ä½¿ç”¨PUTæ–¹æ³•æ›´æ–°æ•°æ®é›†é…ç½®
            response = self.client.put(
                endpoint,
                headers=self.headers,
                json_data=update_data
            )
            
            # æ£€æŸ¥å“åº”
            if isinstance(response, dict):
                if response.get('code') == 0:
                    logger.info(f"âœ… çŸ¥è¯†åº“é…ç½®æ›´æ–°æˆåŠŸ: {kb_name}")
                    return True
                elif response.get('code') == 101:
                    logger.error(f"âŒ é…ç½®å‚æ•°é”™è¯¯: {response.get('message')}")
                    return False
                else:
                    logger.warning(f"âš ï¸ æ›´æ–°å“åº”: {response}")
                    return False
            else:
                logger.warning(f"âš ï¸ æ„å¤–çš„å“åº”æ ¼å¼: {response}")
                return False
                
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“é…ç½®æ›´æ–°å¼‚å¸¸: {e}")
            return False
            
    def _get_knowledge_base_id(self, kb_name: str) -> str:
        """è·å–çŸ¥è¯†åº“ID
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            
        Returns:
            çŸ¥è¯†åº“IDï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
        """
        try:
            response = self.client.get("/api/v1/datasets", headers=self.headers)
            
            if isinstance(response, dict) and response.get('code') == 0:
                for dataset in response.get('data', []):
                    if dataset.get('name') == kb_name:
                        return dataset.get('id')
            
            return None
        except Exception as e:
            logger.error(f"è·å–çŸ¥è¯†åº“IDå¤±è´¥: {e}")
            return None
            
    def _build_dataset_update_payload(self, config_params: dict) -> dict:
        """æ ¹æ®APIæ–‡æ¡£æ„å»ºæ•°æ®é›†æ›´æ–°è½½è·
        
        Args:
            config_params: é…ç½®å‚æ•°
            
        Returns:
            ç¬¦åˆAPIæ–‡æ¡£æ ¼å¼çš„æ›´æ–°æ•°æ®
        """
        # åŸºç¡€æ›´æ–°æ•°æ®
        update_data = {}
        
        # è®¾ç½®åˆ†å—æ–¹æ³•
        chunk_method = "naive"  # é»˜è®¤ä½¿ç”¨Generalæ–¹æ³•
        if config_params.get("pdf_parser") == "deepdoc":
            chunk_method = "naive"  # deepdocå¯¹åº”General
        elif config_params.get("pdf_parser") == "laws":
            chunk_method = "laws"
            
        update_data["chunk_method"] = chunk_method
        
        # æ„å»ºparser_configæ ¹æ®chunk_method
        parser_config = {}
        
        if chunk_method == "naive":
            # Generalæ–¹æ³•çš„parser_config
            parser_config = {
                "chunk_token_num": config_params.get("chunk_size", 800),
                "auto_keywords": 1 if config_params.get("auto_keywords", True) else 0,
                "auto_questions": 0,  # ä¸å¯ç”¨è‡ªåŠ¨é—®é¢˜ç”Ÿæˆ
                "delimiter": "\\n",
                "html4excel": False,
                "layout_recognize": "deepdoc",  # ä½¿ç”¨deepdocå¸ƒå±€è¯†åˆ«
                "task_page_size": 12,
                "raptor": {
                    "use_raptor": config_params.get("graph_retrieval", True),
                    "max_cluster": config_params.get("max_clusters", 50),
                    "max_token": config_params.get("max_tokens", 256),
                    "threshold": config_params.get("similarity_threshold", 0.3),
                    "random_seed": config_params.get("random_seed", 42)
                },
                "graphrag": {
                    "use_graphrag": config_params.get("graph_retrieval", True),
                    "entity_types": ["organization", "person", "geo", "event", "category"],
                    "method": config_params.get("retrieval_mode", "general"),
                    "resolution": config_params.get("entity_normalization", True)
                }
            }
            
        elif chunk_method == "laws":
            # Lawsæ–¹æ³•çš„parser_config (åªæœ‰raptoré…ç½®)
            parser_config = {
                "raptor": {
                    "use_raptor": config_params.get("graph_retrieval", True),
                    "max_cluster": config_params.get("max_clusters", 50), 
                    "max_token": config_params.get("max_tokens", 256),
                    "threshold": config_params.get("similarity_threshold", 0.3),
                    "random_seed": config_params.get("random_seed", 42)
                }
            }
        
        update_data["parser_config"] = parser_config
        
        return update_data

    def check_health(self) -> bool:
        """
        æ£€æŸ¥RAGFlowæœåŠ¡å¥åº·çŠ¶æ€

        åªè¦èƒ½è¿æ¥åˆ°æœåŠ¡å°±è®¤ä¸ºå¥åº·ï¼ˆæŸäº›RAGFlowç‰ˆæœ¬çš„APIè·¯å¾„å¯èƒ½ä¸åŒï¼‰
        """
        try:
            response = requests.get(RAGFLOW_BASE_URL, timeout=5)
            # æœåŠ¡åœ¨çº¿å³ä¸ºå¥åº·ï¼ˆHTTP è¿æ¥æˆåŠŸï¼‰
            return True
        except Exception as e:
            logger.debug(f"RAGFlow å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False

    def upload_document(self, file_path: str, file_name: str,
                       knowledge_base_name: Optional[str] = None) -> Optional[str]:
        """
        ä¸Šä¼ æ–‡æ¡£åˆ°RAGFlow

        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            file_name: æ–‡ä»¶å
            knowledge_base_name: çŸ¥è¯†åº“åç§°ï¼ˆå¦‚ä¸æŒ‡å®šåˆ™ä»config.iniè¯»å–ï¼‰

        Returns:
            æ–‡æ¡£IDï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # å¦‚æœæœªæŒ‡å®šçŸ¥è¯†åº“åç§°ï¼Œä»é…ç½®è¯»å–
            if knowledge_base_name is None:
                knowledge_base_name = config.default_kb_name
            
            with open(file_path, 'rb') as f:
                files = {
                    'file': (file_name, f, self._get_file_mimetype(file_name))
                }

                # æ„å»ºæŸ¥è¯¢å­—ç¬¦ä¸²å‚æ•°
                endpoint = f"{RAGFLOW_ENDPOINTS['upload']}?knowledge_base={knowledge_base_name}"
                
                logger.info(f"ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ '{knowledge_base_name}': {file_name}")

                response = self.client.post(
                    endpoint,
                    headers=self.headers,
                    files=files
                )
                
                logger.debug(f"ä¸Šä¼ å“åº”: {response}")

                # è§£æå“åº”è·å–æ–‡æ¡£ID
                if isinstance(response, dict):
                    # å°è¯•å¤šç§å¯èƒ½çš„å“åº”æ ¼å¼
                    if 'doc_id' in response:
                        logger.info(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {file_name} -> {response['doc_id']}")
                        return response['doc_id']
                    elif 'id' in response:
                        logger.info(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {file_name} -> {response['id']}")
                        return response['id']
                    elif 'data' in response and isinstance(response['data'], dict):
                        data = response['data']
                        if 'doc_id' in data:
                            logger.info(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {file_name} -> {data['doc_id']}")
                            return data['doc_id']
                        elif 'id' in data:
                            logger.info(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ: {file_name} -> {data['id']}")
                            return data['id']
                
                logger.warning(f"æ–‡æ¡£ä¸Šä¼ å“åº”æ ¼å¼å¼‚å¸¸: {response}")
                return None

        except APIError as e:
            logger.error(f"ä¸Šä¼ æ–‡æ¡£å¤±è´¥ (APIError): {e}")
            return None
        except FileNotFoundError as e:
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
        except Exception as e:
            logger.error(f"ä¸Šä¼ æ–‡æ¡£å¼‚å¸¸: {type(e).__name__}: {e}")
            return None

    def delete_document(self, doc_id: str) -> bool:
        """
        åˆ é™¤RAGFlowä¸­çš„æ–‡æ¡£

        Args:
            doc_id: æ–‡æ¡£ID

        Returns:
            Trueè¡¨ç¤ºåˆ é™¤æˆåŠŸ
        """
        try:
            endpoint = RAGFLOW_ENDPOINTS['delete'].replace('{id}', doc_id)
            response = self.client.delete(endpoint, headers=self.headers)
            logger.info(f"æ–‡æ¡£åˆ é™¤æˆåŠŸ: {doc_id}")
            return True
        except APIError as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False

    def search(self, query: str, knowledge_base_name: str = "policy_demo_kb",
               top_k: Optional[int] = None, score_threshold: Optional[float] = None) -> List[Dict[str, Any]]:
        """
        åœ¨RAGFlowä¸­è¿›è¡Œè¯­ä¹‰æœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢
            knowledge_base_name: çŸ¥è¯†åº“åç§°
            top_k: è¿”å›ç»“æœæ•°
            score_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            top_k = top_k or RAGFLOW_SEARCH_CONFIG['top_k']
            score_threshold = score_threshold or RAGFLOW_SEARCH_CONFIG['score_threshold']

            endpoint = RAGFLOW_ENDPOINTS['search']
            data = {
                'query': query,
                'knowledge_base': knowledge_base_name,
                'top_k': top_k,
                'score_threshold': score_threshold,
                'search_type': RAGFLOW_SEARCH_CONFIG['search_type']
            }

            response = self.client.post(endpoint, headers=self.headers, json_data=data)

            # å¤„ç†å“åº”
            results = response.get('results', []) or response.get('data', [])
            logger.info(f"æœç´¢å®Œæˆ: '{query}' è¿”å› {len(results)} ç»“æœ")
            return results

        except APIError as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")
            return []
        except Exception as e:
            logger.error(f"æœç´¢å¼‚å¸¸: {e}")
            return []

    def ask(self, query: str, knowledge_base_name: str = "policy_demo_kb",
            context_limit: int = 5) -> Optional[Dict[str, Any]]:
        """
        åœ¨RAGFlowä¸­è¿›è¡Œé—®ç­”

        Args:
            query: é—®é¢˜
            knowledge_base_name: çŸ¥è¯†åº“åç§°
            context_limit: ä¸Šä¸‹æ–‡é™åˆ¶

        Returns:
            é—®ç­”ç»“æœ
        """
        try:
            endpoint = RAGFLOW_ENDPOINTS['ask']
            data = {
                'question': query,
                'knowledge_base': knowledge_base_name,
                'context_limit': context_limit,
                'max_tokens': RAGFLOW_QA_CONFIG['max_tokens'],
                'temperature': RAGFLOW_QA_CONFIG['temperature']
            }

            response = self.client.post(endpoint, headers=self.headers, json_data=data)
            logger.info(f"é—®ç­”å®Œæˆ: '{query}'")
            return response

        except APIError as e:
            logger.error(f"é—®ç­”å¤±è´¥: {e}")
            return None
        except Exception as e:
            logger.error(f"é—®ç­”å¼‚å¸¸: {e}")
            return None

    def get_documents(self, knowledge_base_name: str = "policy_demo_kb") -> List[Dict[str, Any]]:
        """
        è·å–çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£åˆ—è¡¨

        Args:
            knowledge_base_name: çŸ¥è¯†åº“åç§°

        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        try:
            # é¦–å…ˆè·å–çŸ¥è¯†åº“ID
            dataset_id = self._get_knowledge_base_id(knowledge_base_name)
            if not dataset_id:
                logger.error(f"æœªæ‰¾åˆ°çŸ¥è¯†åº“: {knowledge_base_name}")
                return []
            
            # ä½¿ç”¨æ­£ç¡®çš„API endpointæ ¼å¼
            endpoint = RAGFLOW_ENDPOINTS['documents'].format(dataset_id=dataset_id)
            
            # æ·»åŠ åˆ†é¡µå‚æ•°
            params = {
                'page': 1,
                'page_size': 30,
                'orderby': 'create_time',
                'desc': True
            }
            
            logger.debug(f"è¯·æ±‚æ–‡æ¡£åˆ—è¡¨: {endpoint} å‚æ•°: {params}")
            response = self.client.get(endpoint, headers=self.headers, params=params)

            if isinstance(response, dict):
                if response.get('code') == 0:
                    # æ ¹æ®APIæ–‡æ¡£ï¼Œæ–‡æ¡£åœ¨data.docsä¸­
                    documents = response.get('data', {}).get('docs', [])
                    logger.info(f"è·å–æ–‡æ¡£åˆ—è¡¨æˆåŠŸ: {len(documents)} ä¸ªæ–‡æ¡£")
                    return documents
                else:
                    logger.error(f"APIé”™è¯¯: {response.get('message', 'Unknown error')}")
                    return []
            else:
                logger.error(f"æ„å¤–çš„å“åº”æ ¼å¼: {response}")
                return []

        except APIError as e:
            logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
            return []
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£åˆ—è¡¨å¼‚å¸¸: {e}")
            return []

    def get_document_content(self, doc_id: str) -> Optional[str]:
        """
        è·å–æ–‡æ¡£çš„å®Œæ•´å†…å®¹

        Args:
            doc_id: æ–‡æ¡£ID

        Returns:
            æ–‡æ¡£å†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # RAGFlowå¯èƒ½çš„æ–‡æ¡£å†…å®¹ç«¯ç‚¹
            possible_endpoints = [
                f"/api/v1/documents/{doc_id}/content",
                f"/api/v1/documents/{doc_id}",
                f"/api/documents/{doc_id}/content",
                f"/v1/documents/{doc_id}/content",
            ]
            
            for endpoint in possible_endpoints:
                try:
                    response = self.client.get(endpoint, headers=self.headers)
                    
                    if isinstance(response, dict):
                        # å°è¯•ä»ä¸åŒçš„å“åº”å­—æ®µè·å–å†…å®¹
                        content = (response.get('content') or 
                                 response.get('data', {}).get('content') or
                                 response.get('text'))
                        
                        if content:
                            logger.info(f"æˆåŠŸè·å–æ–‡æ¡£å†…å®¹ (doc_id: {doc_id})")
                            return content
                            
                except APIError as e:
                    if "404" not in str(e):
                        logger.debug(f"ç«¯ç‚¹ {endpoint} å¤±è´¥: {e}")
                    continue
            
            # å¦‚æœæ‰€æœ‰ç›´æ¥ç«¯ç‚¹éƒ½å¤±è´¥ï¼Œå°è¯•é€šè¿‡æœç´¢è·å–å†…å®¹
            logger.info(f"å°è¯•é€šè¿‡æœç´¢è·å–æ–‡æ¡£å†…å®¹: {doc_id}")
            search_results = self.search(f"doc_id:{doc_id}", top_k=50)
            
            if search_results:
                # åˆå¹¶æœç´¢ç»“æœçš„å†…å®¹
                content_parts = []
                for result in search_results:
                    if result.get('content'):
                        content_parts.append(result['content'])
                
                if content_parts:
                    return "\n\n".join(content_parts)
            
            logger.warning(f"æ— æ³•è·å–æ–‡æ¡£å†…å®¹: {doc_id}")
            return None

        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥ (doc_id: {doc_id}): {e}")
            return None

    def get_document_chunks(self, doc_id: str) -> List[Dict[str, Any]]:
        """
        è·å–æ–‡æ¡£çš„åˆ†å—ä¿¡æ¯

        Args:
            doc_id: æ–‡æ¡£ID

        Returns:
            åˆ†å—ä¿¡æ¯åˆ—è¡¨
        """
        try:
            # RAGFlowå¯èƒ½çš„åˆ†å—ç«¯ç‚¹
            possible_endpoints = [
                f"/api/v1/documents/{doc_id}/chunks",
                f"/api/v1/documents/{doc_id}/segments",
                f"/api/documents/{doc_id}/chunks",
                f"/v1/documents/{doc_id}/chunks",
            ]
            
            for endpoint in possible_endpoints:
                try:
                    response = self.client.get(endpoint, headers=self.headers)
                    
                    if isinstance(response, dict):
                        chunks = (response.get('chunks') or 
                                response.get('segments') or
                                response.get('data', []))
                        
                        if chunks:
                            logger.info(f"æˆåŠŸè·å–æ–‡æ¡£åˆ†å— (doc_id: {doc_id}): {len(chunks)} å—")
                            return chunks
                            
                except APIError as e:
                    if "404" not in str(e):
                        logger.debug(f"ç«¯ç‚¹ {endpoint} å¤±è´¥: {e}")
                    continue
            
            logger.warning(f"æ— æ³•è·å–æ–‡æ¡£åˆ†å—: {doc_id}")
            return []

        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£åˆ†å—å¤±è´¥ (doc_id: {doc_id}): {e}")
            return []

    def configure_knowledge_base(self, kb_name: str = None) -> bool:
        """æ‰‹åŠ¨é…ç½®çŸ¥è¯†åº“
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
            
        Returns:
            é…ç½®æ˜¯å¦æˆåŠŸ
        """
        try:
            from src.config import get_config
            
            config = get_config()
            
            if kb_name is None:
                kb_name = config.default_kb_name
            
            # è·å–é…ç½®å‚æ•°
            kb_config = config.ragflow_document_config
            advanced_config = config.ragflow_advanced_config
            full_config = {**kb_config, **advanced_config}
            
            logger.info(f"æ‰‹åŠ¨é…ç½®çŸ¥è¯†åº“: {kb_name}")
            
            return self._update_knowledge_base_config(kb_name, full_config)
            
        except Exception as e:
            logger.error(f"æ‰‹åŠ¨é…ç½®çŸ¥è¯†åº“å¤±è´¥: {e}")
            return False

    def get_knowledge_base_config(self, kb_name: str = None) -> dict:
        """è·å–çŸ¥è¯†åº“å½“å‰é…ç½®
        
        Args:
            kb_name: çŸ¥è¯†åº“åç§°
            
        Returns:
            çŸ¥è¯†åº“é…ç½®å­—å…¸
        """
        try:
            if kb_name is None:
                from src.config import get_config
                config = get_config()
                kb_name = config.default_kb_name
            
            # ä½¿ç”¨æ­£ç¡®çš„APIç«¯ç‚¹è·å–çŸ¥è¯†åº“åˆ—è¡¨ï¼Œç„¶åæ‰¾åˆ°å¯¹åº”çš„çŸ¥è¯†åº“
            endpoint = "/api/v1/datasets"
            
            response = self.client.get(endpoint, headers=self.headers)
            
            if isinstance(response, dict) and response.get('code') == 0:
                datasets = response.get('data', [])
                
                for dataset in datasets:
                    if dataset.get('name') == kb_name:
                        # æå–å…³é”®é…ç½®ä¿¡æ¯
                        config_info = {
                            "çŸ¥è¯†åº“åŸºæœ¬ä¿¡æ¯": {
                                "åç§°": dataset.get('name'),
                                "ID": dataset.get('id'),
                                "çŠ¶æ€": dataset.get('status'),
                                "è¯­è¨€": dataset.get('language'),
                                "åˆ†å—æ–¹æ³•": dataset.get('chunk_method'),
                                "ç›¸ä¼¼åº¦é˜ˆå€¼": dataset.get('similarity_threshold'),
                                "å‘é‡æƒé‡": dataset.get('vector_similarity_weight'),
                                "åµŒå…¥æ¨¡å‹": dataset.get('embedding_model'),
                                "æ–‡æ¡£æ•°é‡": dataset.get('document_count'),
                                "åˆ†å—æ•°é‡": dataset.get('chunk_count')
                            }
                        }
                        
                        # æå–è§£æå™¨é…ç½®
                        parser_config = dataset.get('parser_config', {})
                        if parser_config:
                            config_info["è§£æå™¨é…ç½®"] = {
                                "åˆ†å—Tokenæ•°": parser_config.get('chunk_token_num'),
                                "é‡å ç™¾åˆ†æ¯”": parser_config.get('overlapped_percent'),
                                "è‡ªåŠ¨å…³é”®è¯": parser_config.get('auto_keywords'),
                                "å¯ç”¨å…ƒæ•°æ®": parser_config.get('enable_metadata'),
                                "å¸ƒå±€è¯†åˆ«": parser_config.get('layout_recognize'),
                                "è¡¨æ ¼è§£æ": parser_config.get('mineru_table_enable'),
                                "å…¬å¼è§£æ": parser_config.get('mineru_formula_enable'),
                                "TOCæå–": parser_config.get('toc_extraction')
                            }
                            
                            # æå–å›¾è°±é…ç½®
                            graphrag = parser_config.get('graphrag', {})
                            if graphrag:
                                config_info["å›¾è°±é…ç½®"] = {
                                    "ä½¿ç”¨å›¾è°±": graphrag.get('use_graphrag'),
                                    "æ–¹æ³•": graphrag.get('method'),
                                    "å®ä½“å½’ä¸€åŒ–": graphrag.get('resolution'),
                                    "å®ä½“ç±»å‹": graphrag.get('entity_types')
                                }
                        
                        return config_info
                
                logger.warning(f"åœ¨çŸ¥è¯†åº“åˆ—è¡¨ä¸­æœªæ‰¾åˆ° '{kb_name}'")
                return {}
                
            logger.warning(f"è·å–çŸ¥è¯†åº“åˆ—è¡¨å¤±è´¥: {response}")
            return {}
                
        except Exception as e:
            logger.warning(f"è·å–çŸ¥è¯†åº“é…ç½®å¼‚å¸¸: {e}")
            return {}

    @staticmethod
    def _get_file_mimetype(file_name: str) -> str:
        """æ ¹æ®æ–‡ä»¶åè·å–MIMEç±»å‹"""
        mime_types = {
            '.pdf': 'application/pdf',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.xls': 'application/vnd.ms-excel',
            '.txt': 'text/plain',
            '.md': 'text/markdown'
        }

        # è·å–æ–‡ä»¶æ‰©å±•å
        ext = '.' + file_name.split('.')[-1].lower()
        return mime_types.get(ext, 'application/octet-stream')

    def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        self.client.close()

    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()


# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹
_ragflow_client: Optional[RAGFlowClient] = None


def get_ragflow_client() -> RAGFlowClient:
    """è·å–å…¨å±€RAGFlowå®¢æˆ·ç«¯å®ä¾‹"""
    global _ragflow_client
    if _ragflow_client is None:
        _ragflow_client = RAGFlowClient()
    return _ragflow_client
