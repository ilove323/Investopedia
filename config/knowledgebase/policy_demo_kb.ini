# =====================================================
# 政策库RAGFlow知识库配置
# =====================================================
# 说明：此配置会在系统启动时通过API同步到RAGFlow知识库
# 仅包含RAGFlow API支持的参数

[KNOWLEDGE_BASE]
# 知识库基本信息
name = policy_demo_kb
description = 政策知识库 - 专项债/特许经营/数据资产

# ⚠️ 以下配置需要在RAGFlow Web界面手动设置：
# - Embedding Model（嵌入模型）: 建议使用 BAAI/bge-large-zh-v1.5
#   位置：Knowledge Base > Settings > Embedding model
# - Indexing Model（索引模型）: 无需单独配置，使用Embedding model
# - Permission（权限）: me 或 team

# =====================================================
# 文档分块配置
# =====================================================
[CHUNKING]
# 分块方法 - RAGFlow支持的chunk_method选项：
# naive, qa, manual, table, paper, book, laws, presentation, picture, one, email
chunk_method = laws

# 分块大小（token数）
chunk_size = 1024

# 子分块配置（RAPTOR技术）
# 启用后会创建更小的子分块用于精确检索
child_chunk_enabled = true
child_chunk_size = 256

# =====================================================
# 文档解析配置
# =====================================================
[DOCUMENT_PROCESSING]
# 版面识别方法
# 选项：deepdoc（深度文档解析，保留格式和结构）
layout_recognize = deepdoc

# =====================================================
# 检索配置（RAGFlow Chat Assistant设置）
# =====================================================
[RETRIEVAL]
# 相似度阈值 - chunks相似度低于此值会被过滤
# 默认0.2，较低值召回更多结果
similarity_threshold = 0.3

# 向量相似度权重
# 混合检索中向量相似度的权重（剩余为关键词权重）
# 默认0.3
vector_similarity_weight = 0.3

# Top K - 参与向量余弦计算的chunk数量
# 默认1024
top_k = 1024

# Top N - 最终返回给LLM的chunk数量
# 默认8
top_n = 8

# 重排序模型（可选）
# 如不指定则使用向量余弦相似度，指定后使用重排序分数
# rerank_model = bge-reranker-large

# =====================================================
# 问答配置（RAGFlow Chat Assistant LLM设置）
# =====================================================
[QA]
# LLM模型（格式：model_name@model_factory）
# 示例：gpt-4-turbo-preview@OpenAI, glm-4-flash@ZHIPU-AI
qa_model = gpt-4-turbo-preview

# LLM生成参数
temperature = 0.1
top_p = 0.9
max_tokens = 2000

# 系统提示词
# 需要将提示词内容放在 config/prompts/policy_demo_kb.txt
system_prompt_file = policy_demo_kb.txt